{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb29edca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D,Dropout\n",
    "from keras.models import Model, Sequential,load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "983183d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a4ebb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 4 classes.\n",
      "Found 3112 images belonging to 4 classes.\n",
      "Found 2500 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set=train_datagen.flow_from_directory(\n",
    "    r\"",
    "    target_size=(128,128),\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "test_set=test_datagen.flow_from_directory(\n",
    "    r\"",
    "    target_size=(128,128),\n",
    "    batch_size=64,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "validation_set=validation_datagen.flow_from_directory(\n",
    "   r\"",
    "    target_size=(128,128),\n",
    "    batch_size=64,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b179834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dropout layer\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Dense layers\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))  # Assuming binary classification, change this for multi-class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ced4999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['",
       " '",
       " '",
       " '\']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder=glob(r\"",
    "folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf4b1fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28482ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8505d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint('model_checkpoint_epoch_{epoch:02d}.h5',\n",
    "                                       save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d39a4439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 126, 126, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPooli  (None, 63, 63, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 61, 61, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPooli  (None, 30, 30, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 28, 28, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPooli  (None, 14, 14, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPooli  (None, 6, 6, 128)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPooli  (None, 2, 2, 256)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 656036 (2.50 MB)\n",
      "Trainable params: 656036 (2.50 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3448cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "803514d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "157/157 [==============================] - 177s 1s/step - loss: 1.0536 - accuracy: 0.5146 - val_loss: 0.8579 - val_accuracy: 0.6224\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 190s 1s/step - loss: 0.6662 - accuracy: 0.7367 - val_loss: 0.6256 - val_accuracy: 0.7668\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 180s 1s/step - loss: 0.5193 - accuracy: 0.8007 - val_loss: 0.4593 - val_accuracy: 0.8336\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 183s 1s/step - loss: 0.4548 - accuracy: 0.8265 - val_loss: 0.3803 - val_accuracy: 0.8608\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 184s 1s/step - loss: 0.3685 - accuracy: 0.8630 - val_loss: 0.3495 - val_accuracy: 0.8744\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 196s 1s/step - loss: 0.3128 - accuracy: 0.8850 - val_loss: 0.2954 - val_accuracy: 0.8840\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 186s 1s/step - loss: 0.2676 - accuracy: 0.9004 - val_loss: 0.2865 - val_accuracy: 0.8844\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 191s 1s/step - loss: 0.2594 - accuracy: 0.9045 - val_loss: 0.2195 - val_accuracy: 0.9168\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 217s 1s/step - loss: 0.2187 - accuracy: 0.9185 - val_loss: 0.2439 - val_accuracy: 0.9028\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 186s 1s/step - loss: 0.1739 - accuracy: 0.9391 - val_loss: 0.2031 - val_accuracy: 0.9200\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 185s 1s/step - loss: 0.1704 - accuracy: 0.9346 - val_loss: 0.1688 - val_accuracy: 0.9380\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 185s 1s/step - loss: 0.1368 - accuracy: 0.9487 - val_loss: 0.1510 - val_accuracy: 0.9460\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 188s 1s/step - loss: 0.1370 - accuracy: 0.9479 - val_loss: 0.1364 - val_accuracy: 0.9520\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 193s 1s/step - loss: 0.1149 - accuracy: 0.9581 - val_loss: 0.1146 - val_accuracy: 0.9580\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 186s 1s/step - loss: 0.0941 - accuracy: 0.9670 - val_loss: 0.1023 - val_accuracy: 0.9616\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 189s 1s/step - loss: 0.0892 - accuracy: 0.9685 - val_loss: 0.2117 - val_accuracy: 0.9256\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 256s 2s/step - loss: 0.0925 - accuracy: 0.9683 - val_loss: 0.1050 - val_accuracy: 0.9600\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 185s 1s/step - loss: 0.0740 - accuracy: 0.9719 - val_loss: 0.1325 - val_accuracy: 0.9564\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 186s 1s/step - loss: 0.0640 - accuracy: 0.9775 - val_loss: 0.0969 - val_accuracy: 0.9692\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 183s 1s/step - loss: 0.0611 - accuracy: 0.9776 - val_loss: 0.0980 - val_accuracy: 0.9632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25ea09e1160>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    training_set, \n",
    "    validation_data=validation_set, \n",
    "    epochs=total_epochs,\n",
    "    validation_steps=len(validation_set), \n",
    "    steps_per_epoch=len(training_set),\n",
    "    callbacks= [checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602bbe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "model.load_weights('model_checkpoint_epoch_16.h5')\n",
    "model.fit(training_set, validation_data=validation_set, epochs=total_epochs + n,\n",
    "                          validation_steps=len(validation_set), steps_per_epoch=len(training_set),\n",
    "                          initial_epoch = 16,\n",
    "                          callbacks= [checkpoint_callback]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c00ccad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"Lord_cnn.h5\")\n",
    "from tensorflow.keras.models import load_model\n",
    "modelcnn=load_model(\"Lord_cnn.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a706c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
